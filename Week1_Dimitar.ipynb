{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eggressive/Learning-AI-with-Copilot/blob/main/Week1_Dimitar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Week 1 - PyTorch and MLPs** (~1 hr total)\n",
        "\n"
      ],
      "metadata": {
        "id": "OwkdvS4Nd8ux"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 0 - Setup (~1 min)\n",
        "\n",
        "**Before you begin, please clone this notebook!**\n",
        "\n",
        "*File > Save a copy in Drive*\n",
        "\n",
        "Then, go to the `DLE-Jun23` Drive [folder link](https://drive.google.com/drive/folders/1G960JEYYy646Gn_4Xxm_W5jYjHBwlglS?usp=drive_link), click the down arrow next to DLE-Jun23, and select \"Add shortcut to Drive\". Make sure the shortcut is added to \"My Drive\".\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=download&id=1y2OCLuw7Ux2h10HQSVpT0s5c2k1JPGS-\"  width=\"300\">"
      ],
      "metadata": {
        "id": "WfeNp0JxocE2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from logging import exception\n",
        "#@title Step 1: Mount drive\n",
        "#@markdown Run this cell. If prompted, press \"Connect to Google Drive\" and select your Google account.\n",
        "#@markdown Then, under the folder icon üìÅ on the left panel, you should see the folder **drive** appear.\n",
        "from google.colab import drive\n",
        "from IPython.display import display, Markdown, HTML\n",
        "import os, sys\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "try:\n",
        "  drive.mount('/content/drive', force_remount=False)\n",
        "  sys.path.append('/content/drive/MyDrive/DLE-Jun23/Projects')\n",
        "  os.chdir('/content/drive/MyDrive/Colab Notebooks/')\n",
        "  display(\"‚≠ê Mounted successfully!\")\n",
        "except:\n",
        "  display(HTML('<span style=\"color:red\">An error occurred. Try again!</span>'))\n"
      ],
      "metadata": {
        "id": "u3fm6NNHBMr5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "1b3a9dce-0db9-4d13-9d4c-432863412687"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'‚≠ê Mounted successfully!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Import packages"
      ],
      "metadata": {
        "id": "quEFcn37Q8Ak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "!pip install gradio\n",
        "from dle_utils.dle_utils import *\n",
        "\n",
        "import gradio as gr\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(0)\n",
        "torch.manual_seed(0)"
      ],
      "metadata": {
        "id": "0QlX3-fFmHLk"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Step 3: Enter your name to begin\n",
        "#@markdown Enter your name as it appears in Slack and run this cell! (Optional; this allows us gain insight into your progress. You can also leave this blank.)\n",
        "Name = 'Dimitar Dimitrov' #@param {type:\"string\"}\n",
        "filepath = '/content/drive/MyDrive/Colab Notebooks/dle_info.txt'\n",
        "if os.path.exists(filepath):\n",
        "  print(\"Success!\")\n",
        "else:\n",
        "  if len(Name) == 0:\n",
        "    print(\"Please set your name!\")\n",
        "  else:\n",
        "    try:\n",
        "      with open(filepath, 'w') as fp:\n",
        "        fp.write(Name)\n",
        "        dle_username = Name\n",
        "      print(\"Success!\")\n",
        "    except:\n",
        "      print(\"Something went wrong...\")\n"
      ],
      "metadata": {
        "id": "sxYKrTzuer1C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cafccdf-c54a-4e53-81f0-862e9eb68c3e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note**: Most cells contains a `check` function that provides feedback on your solution (correct or incorrect). We've designed these for your benefit to know that you are on the right track! Even if you are stuck on one section, we encourage you to continue as a failed check does not prevent you from continuing. Though we have worked to make each check as comprehensive as possible, PyTorch may from time to time have unexpected random behaviors. Please reach out to the instructors if you think your answer should be passing a check!"
      ],
      "metadata": {
        "id": "ZWMw3Kms-KzG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1 - PyTorch Basics (~30 min)\n",
        "\n",
        "## *Tensor < Layer < Network*\n",
        "\n",
        "In PyTorch, a **tensor** is the fundamental data structure for storing and manipulating data, a **layer** is a neural network component that performs a specific computation on the input tensors and produces output tensors, and a **network** (also known as a model) is a collection of layers that are organized in a specific way to perform a specific task, such as image classification or machine translation.\n"
      ],
      "metadata": {
        "id": "kHx3e30YXmW4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Tensors\n",
        "\n",
        "PyTorch has its own classes for arrays and data, similar to how Numpy has objects like np.array. In order to perform PyTorch operations, we just to convert data into a PyTorch Tensor (torch.Tensor).\n",
        "\n",
        "For reference, PyTorch tensors are covered in the following documentation: https://pytorch.org/docs/stable/tensors.html\n",
        "\n",
        "This link will be very helpful for answering the following questions.\n",
        "\n",
        "### **10 quick exercises in PyTorch tensor operations:**"
      ],
      "metadata": {
        "id": "qk4BWNiM04bI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) Create a 3x6 tensor with ones:"
      ],
      "metadata": {
        "id": "c31zOlhqDGmV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = torch.ones((3, 6))\n",
        "check('1.1.1', A)"
      ],
      "metadata": {
        "id": "bgPulloLDN14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "outputId": "6ce9d54e-af60-48cc-e212-3ee4f5481e5e"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Correct! üéâ"
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) Create a 3x6 tensor with random values:"
      ],
      "metadata": {
        "id": "N-CfhHrsDPl5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(0)\n",
        "B = torch.rand((3, 6))\n",
        "check('1.1.2', B)"
      ],
      "metadata": {
        "id": "dbmIfUMzDPl5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "outputId": "1950b595-bace-414e-d2e5-14dc2e5085e7"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Correct! üéâ"
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) Transpose B:"
      ],
      "metadata": {
        "id": "-5mwZ6PSEEqk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "B_T = torch.t(B)\n",
        "check('1.1.3', B_T)"
      ],
      "metadata": {
        "id": "WTtHApYVEEql",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "outputId": "7d49962d-642b-4e71-e9c0-891943d4ed54"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Correct! üéâ"
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4) Evaluate the following expression:\n",
        "\n",
        "$$C = (B-A)^T(B)$$\n",
        "\n",
        "That is, the product of two matrices: $(B-A)$ transposed, and B.\n",
        "Hint: Are A and B the same data type?"
      ],
      "metadata": {
        "id": "Yx94n0foDP2P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cast both to float tensors\n",
        "A = A.type(torch.FloatTensor)\n",
        "B = B.type(torch.FloatTensor)\n",
        "C = torch.mm((B - A).t(), B)\n",
        "check('1.1.4', C)"
      ],
      "metadata": {
        "id": "72--iLIjDP2P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "outputId": "1d38fb85-8364-4d42-b69a-cbaabdcc7691"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Correct! üéâ"
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5) Reshape C into shape (6,2,3):"
      ],
      "metadata": {
        "id": "LmSXk5wZEEyi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "D = C.view(6, 2, 3)\n",
        "\n",
        "check('1.1.5', D)"
      ],
      "metadata": {
        "id": "dMokyB36EEyi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "outputId": "0df1d10f-5477-40e2-ff72-475f9a067ab9"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Correct! üéâ"
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6) Slice the tensor `D` along axis 1 and select the first element:"
      ],
      "metadata": {
        "id": "U3EAAdx6E759"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "D_ = D[:,0,:]\n",
        "check('1.1.6', D_)"
      ],
      "metadata": {
        "id": "0chvcKM9EE6t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "outputId": "39ca1cf9-80b4-4dab-d25c-893aed1abc8c"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Correct! üéâ"
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7) Concatenate tensors `B` and `C` along axis 0:"
      ],
      "metadata": {
        "id": "8jZhfrg5EFBU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "B_C = torch.cat((B, C), dim=0)\n",
        "check('1.1.7', B_C)"
      ],
      "metadata": {
        "id": "g4t1FBLTEFBU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "outputId": "f3bbf925-a453-4bc3-a846-fe9fdb466c59"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Correct! üéâ"
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8) Create a NumPy array with random uniform values of size (4,4). Convert it to a PyTorch tensor:\n",
        "\n",
        "Hint: Use `numpy.random.rand()`!"
      ],
      "metadata": {
        "id": "W0sfMsYqFkQn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(0)\n",
        "# Create 4x4 NumPy array with random uniform values\n",
        "np_array = np.random.rand(4,4)\n",
        "# Convert to PyTorch tensor\n",
        "N = torch.from_numpy(np_array)\n",
        "check('1.1.8', N)"
      ],
      "metadata": {
        "id": "J-fAkHV0FkQn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "outputId": "9287f2dc-c8fc-44fa-847a-fa720ca733fa"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Correct! üéâ"
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9) Convert tensor `N` back into a Numpy array:"
      ],
      "metadata": {
        "id": "jFY-iFMzFkZa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N_A = N.numpy()\n",
        "check('1.1.9', N_A)"
      ],
      "metadata": {
        "id": "rGUTTwqfFkZa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "outputId": "a02bcfd1-74e5-48de-9dff-19510915c967"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Correct! üéâ"
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10) Set the value of the number in the 1st row, 2nd column of `N` to 20:"
      ],
      "metadata": {
        "id": "_UiojMgiFkgz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N[0, 1] = 20\n",
        "check('1.1.10', N)"
      ],
      "metadata": {
        "id": "sAdkiyJJFkg0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "outputId": "181630fa-c985-4196-d78d-fb44553fa4c5"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Correct! üéâ"
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Layers\n",
        "\n",
        "A tensor is the input and output of a layer. The layer applies a specific operation or transformation on the input tensor(s) to produce an output tensor. A network is made up of multiple layers, where the output of one layer is used as the input to the next layer.\n",
        "\n",
        "When we create an instance of a layer (`nn.Linear`), the weights are randomly initialized. Through training, these weights become tuned to the task at hand.\n",
        "\n",
        "You can access the actual weights themselves using `.weight`. The weights are PyTorch Parameters (object type `torch.nn.parameter.Parameter`), which are essentially `torch.Tensor` objects with requires_grad=True. The same is true of the bias, which is stored in `.bias`.\n",
        "\n",
        "### **5 quick exercises in PyTorch layers!**"
      ],
      "metadata": {
        "id": "a_yb_zYJ08Gs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) Create a `nn.Linear` layer with 10 input features and 5 output features and a bias term."
      ],
      "metadata": {
        "id": "6w4uJmQO6o0M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer = nn.Linear(10, 5)\n",
        "\n",
        "check('1.2.1', layer)"
      ],
      "metadata": {
        "id": "P4DV8v2c2BfL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "outputId": "4ad4e2c2-e4f4-4001-f5b1-5bc4218c6f5d"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Correct! üéâ"
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) Create a 3x10 input tensor (call it `x`) filled with ones and perform a forward pass through `layer`, storing the result in `output`."
      ],
      "metadata": {
        "id": "5gYJW_RO75MD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.ones((3, 10))\n",
        "output = layer(x)\n",
        "print(output.shape)\n",
        "check('1.2.2', output)"
      ],
      "metadata": {
        "id": "AzRcZR9p66wZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        },
        "outputId": "1357d39b-0b34-43fd-e128-9e3b056cd1c8"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 5])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Correct! üéâ"
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) Print the shape of the weights and biases of `layer`. Then, modify the parameters: multiply each of the weight values by 1.2, and add 5 to each of the bias values. Then, perform a forward pass again through `layer` with the tensor `x` and store the result in `output`.\n",
        "\n",
        "Hint: When modifying parameters, you should do so within a block that disables gradients like such:\n",
        "\n",
        "```\n",
        "with torch.no_grad():\n",
        "  ...\n",
        "````"
      ],
      "metadata": {
        "id": "Cm6eaLUx8BKA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(0)\n",
        "print(f\"Weights shape: {layer.weight.shape}\") # access the weights\n",
        "print(f\"Biases shape: {layer.bias.shape}\") # access the biases\n",
        "# Modify parameters\n",
        "with torch.no_grad():\n",
        "    layer.weight *= 1.2\n",
        "    layer.bias += 5\n",
        "output = layer(x)\n",
        "check('1.2.3', output)"
      ],
      "metadata": {
        "id": "A492Ad7X7hyc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99
        },
        "outputId": "ed250be1-0ef2-4364-c7c9-c95ac4c8331e"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights shape: torch.Size([5, 10])\n",
            "Biases shape: torch.Size([5])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Correct! üéâ"
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4) Under the hood, `Linear` layers perform a very simple operation: for an input `x`, it computes the dot product with the `weights` matrix, and then adds the `bias` vector.\n",
        "\n",
        "Write an expression in Numpy that uses `layer.weight` and `layer.bias` to reproduce the same output as `layer`.\n",
        "\n",
        "**Hint**: Consult the [`nn.Linear`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html) docs page to see the formula used.\n",
        "\n",
        "**Hint**: Try to access the weights directly as a Numpy array with `layer.weight.numpy()`. What error do you get? Try the suggested fix in the error message!"
      ],
      "metadata": {
        "id": "C0W4AYj-8C2O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = np.dot(\n",
        "           x.detach().numpy(),\n",
        "           layer.weight.detach().numpy().T) + layer.bias.detach().numpy()\n",
        "\"\"\"\n",
        "It was very difficult to figure out I need to transpose one of the arrays so their shapes are compatible.\n",
        "Since x kept showing correct shape, the only option I found was to  transpose the layer.weight.\n",
        "\"\"\"\n",
        "check('1.2.4', output)"
      ],
      "metadata": {
        "id": "liGCDAdG_65h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "outputId": "020fd741-37ba-4cc7-d64d-d8e4f8818e45"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Correct! üéâ"
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5) Activation functions\n",
        "\n",
        "The final piece of a layer is the activation function, which performs an element-wise transform of a layer's outputs.\n",
        "\n",
        "Add a `torch.nn.ReLU` activaton function to `layer`. Then, pass `x` through both and store the result in `output`.\n"
      ],
      "metadata": {
        "id": "czUQa8vFSc-J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(0)\n",
        "layer = torch.nn.Linear(10, 5, bias=True) # re-initializing layer with the original weights\n",
        "# Add ReLU activation\n",
        "layer = nn.Sequential(\n",
        "    layer,\n",
        "    nn.ReLU()\n",
        ")\n",
        "output = layer(x)\n",
        "\n",
        "check('1.2.5', output)"
      ],
      "metadata": {
        "id": "Jy4O9CqpSdXA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "outputId": "570b1646-f475-4cdb-aeaa-2c5e9652cc74"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Correct! üéâ"
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Neural Network\n",
        "\n",
        "A **neural network** takes a *tensor* as input, applies a series of transformations defined by the *layers*, and produces an output *tensor*, which can be used to make predictions or perform other tasks. The layers in a network are organized in a specific way, such as in a sequential or parallel fashion, to perform a specific task.\n",
        "\n",
        "### **3 quick exercises for neural networks:**"
      ],
      "metadata": {
        "id": "Q5jgE-aW09iq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) Create three layers with the following input and output features:\n",
        "\n",
        "- 10 inputs, 10 outputs\n",
        "- 10 inputs, 20 outputs\n",
        "- 20 inputs, 1 output\n",
        "\n",
        "Let each of the layers include bias terms.\n",
        "\n",
        "Then, let `x` be an input tensor with shape (5,10) and random values and make a forward pass through each of the layers sequentially, assigning the result to `output`.\n",
        "\n",
        "**Hint**: When creating random tensors, we suggest you use the `torch` library directly!"
      ],
      "metadata": {
        "id": "akdBXLvC2_Qs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(0)\n",
        "# declare your layers first\n",
        "layer1 = torch.nn.Linear(10, 10, bias=True)\n",
        "layer2 = torch.nn.Linear(10, 20, bias=True)\n",
        "layer3 = torch.nn.Linear(20, 1, bias=True)\n",
        "# then, create your input tensor\n",
        "x = torch.rand(5, 10)\n",
        "# finally, evaluate your output\n",
        "output = layer1(x)\n",
        "output = layer2(output)\n",
        "output = layer3(output)\n",
        "check('1.3.1', output)"
      ],
      "metadata": {
        "id": "85f1WEzEYl95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "outputId": "b9389336-91f8-4226-b3cc-f2f191285a9f"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Correct! üéâ"
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) Now, add `nn.ReLU()` activation functions after each of the first two layers (2 functions total). You've just defined a simple neural network!"
      ],
      "metadata": {
        "id": "V31YtMBWYRj7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "# Add ReLU after first layer\n",
        "output = layer1(x)\n",
        "output = torch.relu(output)\n",
        "\n",
        "# Add ReLU after second layer\n",
        "output = layer2(output)\n",
        "output = torch.relu(output)\n",
        "\n",
        "output = layer3(output)\n",
        "check('1.3.2', output)"
      ],
      "metadata": {
        "id": "w03FLgzT81l6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "outputId": "909b2a2e-a62f-4d39-d78d-010907061187"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Correct! üéâ"
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) A PyTorch [`nn.Module`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html) is the base class for all neural network modules in PyTorch, which can be used to define a layer. The nn.Module class also provides a way to organize multiple layers and other modules in a way that defines a complete neural network.\n",
        "\n",
        "**TODO**: Create a `nn.Module` class with the neural network above and call it `MLP`. Instantiate it and assign it to the `model` variable.\n",
        "\n",
        "**Hint**: You will define an `__init__()` function, which will create the layer variables, and a `forward()` function, which takes as an input argument a tensor and returns the output of the neural network. Though using `nn.Sequential()` is a valid way to build the layers, we encourage you for this exercise to define each layer individually."
      ],
      "metadata": {
        "id": "G12lekEDYX3y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "S-4V4jABAGR2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2004cd3f-254d-42c2-912a-21e44e1e2169"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 1])\n",
            "Parameter containing:\n",
            "tensor([[-0.0024,  0.1696, -0.2603, -0.2327, -0.1218,  0.0848, -0.0063,  0.2507,\n",
            "         -0.0281,  0.0837],\n",
            "        [-0.0956, -0.0622, -0.3021, -0.2094, -0.1304,  0.0117,  0.1250,  0.1897,\n",
            "         -0.2144, -0.1377],\n",
            "        [ 0.1149,  0.2626, -0.0651,  0.2366, -0.0510,  0.0335,  0.2863, -0.2934,\n",
            "         -0.1991, -0.0801],\n",
            "        [-0.1233,  0.2732, -0.2050, -0.1456, -0.2209, -0.2962, -0.1846,  0.2718,\n",
            "          0.1411,  0.1533],\n",
            "        [ 0.0166, -0.1621,  0.0535, -0.2953, -0.2285, -0.1630,  0.1995,  0.1854,\n",
            "         -0.1402, -0.0114],\n",
            "        [ 0.2022,  0.3144,  0.1255,  0.0427,  0.2120, -0.1862,  0.0589, -0.2452,\n",
            "         -0.2192, -0.1634],\n",
            "        [ 0.1431,  0.1272, -0.1873,  0.0955,  0.1736, -0.0399,  0.0121,  0.0733,\n",
            "          0.1962,  0.3036],\n",
            "        [-0.2437, -0.1159,  0.1243,  0.2620,  0.2752,  0.2790,  0.0629, -0.2750,\n",
            "          0.0291, -0.1978],\n",
            "        [-0.2947,  0.2810,  0.2404, -0.3154,  0.0592, -0.0533, -0.0520, -0.1448,\n",
            "          0.1216, -0.1873],\n",
            "        [ 0.1159,  0.1599,  0.2264,  0.1182, -0.3130, -0.2051,  0.1579,  0.0662,\n",
            "         -0.2467, -0.1821]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 0.2975,  0.2131, -0.1379, -0.0796, -0.3012, -0.0057, -0.2381, -0.2439,\n",
            "        -0.0174,  0.0475], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.1295,  0.1876, -0.1924,  0.2869,  0.2167, -0.2667, -0.0787,  0.0143,\n",
            "          0.0461,  0.0750],\n",
            "        [ 0.1241,  0.0189, -0.1543,  0.1496, -0.3033, -0.1874, -0.0792, -0.1540,\n",
            "         -0.1106, -0.2592],\n",
            "        [-0.0673,  0.0676, -0.2060, -0.0162,  0.2264, -0.0325,  0.0088, -0.0273,\n",
            "          0.0640,  0.2011],\n",
            "        [ 0.2995,  0.2008,  0.3002, -0.0229, -0.2841, -0.1499,  0.2153, -0.0020,\n",
            "         -0.1572, -0.2423],\n",
            "        [-0.2959, -0.2669, -0.0641,  0.1734,  0.1710, -0.3050,  0.1973, -0.2475,\n",
            "         -0.0669, -0.1282],\n",
            "        [-0.0609, -0.0621, -0.2838, -0.2730, -0.0495,  0.0041, -0.1437,  0.1191,\n",
            "         -0.2846, -0.0213],\n",
            "        [ 0.2781, -0.1290,  0.2856,  0.1145, -0.2854,  0.2001, -0.0365, -0.1412,\n",
            "          0.2529, -0.2555],\n",
            "        [ 0.0339, -0.0662,  0.2258,  0.0883,  0.1519,  0.1117, -0.0760, -0.0665,\n",
            "         -0.2606,  0.1713],\n",
            "        [ 0.2511,  0.2164, -0.2231,  0.0141, -0.2229, -0.1741, -0.1843,  0.1081,\n",
            "         -0.1884, -0.0069],\n",
            "        [ 0.0133,  0.2038, -0.2390, -0.2171, -0.1836,  0.2213, -0.1137,  0.2667,\n",
            "          0.1144,  0.0400],\n",
            "        [-0.0024, -0.0625,  0.0397, -0.0722, -0.0022,  0.0403, -0.2474, -0.1657,\n",
            "          0.2554, -0.2566],\n",
            "        [-0.0227,  0.3128,  0.1142,  0.0090, -0.2740,  0.1567, -0.2252, -0.0898,\n",
            "         -0.1061, -0.0468],\n",
            "        [ 0.0035,  0.2608,  0.0395,  0.2832,  0.1934, -0.1999,  0.1418, -0.2235,\n",
            "         -0.1340,  0.0930],\n",
            "        [ 0.1044,  0.2372, -0.1018,  0.0005,  0.1628, -0.3058,  0.2286, -0.2615,\n",
            "          0.0044, -0.0538],\n",
            "        [-0.1665,  0.0418,  0.2615, -0.0924, -0.1877, -0.1170, -0.3134,  0.1427,\n",
            "         -0.1519, -0.2110],\n",
            "        [-0.1822,  0.1818,  0.1675,  0.2427,  0.1147, -0.1056, -0.0884,  0.0934,\n",
            "          0.2600,  0.0860],\n",
            "        [-0.1496, -0.1487, -0.2990,  0.0683, -0.1775, -0.2819,  0.2773, -0.2054,\n",
            "         -0.0360,  0.0906],\n",
            "        [ 0.0101, -0.2128, -0.2556,  0.2521,  0.0515,  0.2624, -0.1060,  0.0931,\n",
            "         -0.0723, -0.0141],\n",
            "        [-0.1926,  0.1069,  0.1000, -0.0065, -0.0711, -0.1949,  0.2187, -0.2354,\n",
            "          0.1295, -0.1063],\n",
            "        [-0.1526,  0.0568, -0.1643,  0.0729,  0.0621, -0.2348,  0.0527,  0.1347,\n",
            "          0.1252, -0.0398]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.2592, -0.0487,  0.1098, -0.1154,  0.1200,  0.2106, -0.1651,  0.0031,\n",
            "         0.1308,  0.0248,  0.0264,  0.0395, -0.2486,  0.0249,  0.2190,  0.2850,\n",
            "         0.1859,  0.0424,  0.1477, -0.1538], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.1853, -0.1923,  0.2231,  0.1419, -0.1546,  0.0875,  0.1689,  0.2235,\n",
            "          0.1955,  0.1732, -0.0513, -0.0785,  0.1836,  0.1253, -0.1346,  0.2010,\n",
            "          0.1080,  0.1219, -0.1402,  0.0642]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0784], requires_grad=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Sorry, try again! ü§≠"
          },
          "metadata": {},
          "execution_count": 102
        }
      ],
      "source": [
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "\n",
        "\"\"\"\n",
        "unsure what is failing here? Code checks out!\n",
        "It is also possible to\n",
        "eg:\n",
        "  x = torch.rand(128, 10) # Input data\n",
        "  output = model(x) # Perform forward pass\n",
        "\"\"\"\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "\n",
        "        # layers of the network\n",
        "        self.layer1 = nn.Linear(10, 10, bias=True)\n",
        "        self.layer2 = nn.Linear(10, 20, bias=True)\n",
        "        self.layer3 = nn.Linear(20, 1, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # defininiton of the computations of the network\n",
        "        x = torch.relu(self.layer1(x))\n",
        "        x = torch.relu(self.layer2(x))\n",
        "        x = self.layer3(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "model = MLP()\n",
        "# added check to print the output shape\n",
        "x = torch.rand(128, 10) # Input data\n",
        "output = model(x) # Perform forward pass\n",
        "print(output.shape)\n",
        "\n",
        "# added check to print the model parameters\n",
        "for param in model.parameters():\n",
        "    print(param)\n",
        "check('1.3.3', model)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Gradients\n",
        "\n",
        "Congratulations! You've created your first PyTorch neural network! üéâüéâüéâ\n",
        "\n",
        "We now know how each layer transforms tensors and produces outputs. This is called a *forward pass*, as the computations performed on the input tensor are moving forward across the network.\n",
        "\n",
        "**But, how does a neural network learn?** It does so by performing a *backward pass*.\n",
        "\n",
        "In a *backward pass*, the gradients for each parameter are computed, starting with the last layer and moving backward. This algorithm is called *backpropagation*, which uses the chain rule to calculate gradients."
      ],
      "metadata": {
        "id": "QBciwraL2SUo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) Consider the following equation:\n",
        "\n",
        "$y = 3x^2+3$\n",
        "\n",
        "**Quick concept check: answer the questions below, and click the arrow to reveal the answer!**\n",
        "\n",
        "<details><summary>What is $\\frac{dy}{dx}$?</summary>\n",
        "     6x\n",
        "</details>\n",
        "\n",
        "<details><summary>What is $\\frac{dy}{dx}(2)$?</summary>\n",
        "     12\n",
        "</details>"
      ],
      "metadata": {
        "id": "8YlSm7F6J1a8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) Let's implement the same equation in PyTorch and verify that it does the same thing!\n",
        "\n",
        "- Create a tensor `x` with value 2.0 and set `requires_grad=True`.\n",
        "\n",
        "- Write the equation above in Python ($y=3x^2+3$).\n",
        "\n",
        "- Then, call `y.backward()`. This step computes the gradient of `y` with respect to the change in `x` at the value of `x=2.0`. It also stores the gradient in `x.grad`.\n",
        "\n",
        "- Print `x.grad`. Confirm that it equals the same value you got above for $\\frac{dy}{dx}(2)$!\n"
      ],
      "metadata": {
        "id": "f_lvj_bu2e5y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(2.0, requires_grad=True)\n",
        "y = 3*x**2 + 3\n",
        "y.backward()\n",
        "x.grad\n",
        "print(x.grad)\n",
        "check('1.4.2', x.grad)"
      ],
      "metadata": {
        "id": "odnmAW_XnNtK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        },
        "outputId": "084f3eb7-45b9-43ed-9bef-c9fc9933ef4f"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(12.)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Correct! üéâ"
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) Cool! We've checked for a simple example that PyTorch automatically computes and stores gradients with the `backward()` function. Now let's see gradients in action in our newly created MLP.\n",
        "\n",
        "**TODO**:\n",
        "\n",
        "- Instantiate the `MLP` class into the `model` variable. Be sure to do this first!\n",
        "- Create a random tensor `x` that is size 10 and run a forward pass through the model, storing the result in `output`.\n",
        "- Print the `.grad` attribute in the first layer's weights. What is the value?\n",
        "- Then, run the `.backward()` pass on the `output` tensor. Now, print the `.grad` attribute again on the first layer's weights. What do you get this time?"
      ],
      "metadata": {
        "id": "g6Uz6Ezm6dgZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(0)\n",
        "# first, create your model\n",
        "model = MLP()\n",
        "# then, create your input tensor\n",
        "x = torch.rand(10)\n",
        "# then, get the model output\n",
        "output = model(x)\n",
        "# print the gradient\n",
        "print(model.layer1.weight.grad)\n",
        "# run the backward pass\n",
        "output.backward()\n",
        "# finally, print the gradient again\n",
        "print(model.layer1.weight.grad)\n",
        "check('1.4.3', model.layer1.weight.grad)"
      ],
      "metadata": {
        "id": "3cMF1yjiJq39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "outputId": "61902364-5eb6-4be2-b382-b9a2eeb3b6aa"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "tensor([[ 0.0748,  0.0344,  0.0584,  0.0495,  0.0599,  0.0277,  0.0625,  0.0127,\n",
            "          0.0515,  0.0136],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000],\n",
            "        [-0.1633, -0.0752, -0.1274, -0.1080, -0.1307, -0.0605, -0.1364, -0.0276,\n",
            "         -0.1124, -0.0297],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000],\n",
            "        [ 0.0718,  0.0330,  0.0560,  0.0474,  0.0574,  0.0266,  0.0599,  0.0121,\n",
            "          0.0494,  0.0130],\n",
            "        [-0.0760, -0.0350, -0.0593, -0.0503, -0.0608, -0.0282, -0.0635, -0.0129,\n",
            "         -0.0523, -0.0138],\n",
            "        [ 0.1103,  0.0508,  0.0860,  0.0729,  0.0883,  0.0409,  0.0921,  0.0187,\n",
            "          0.0759,  0.0200],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000],\n",
            "        [ 0.1595,  0.0734,  0.1244,  0.1054,  0.1276,  0.0591,  0.1332,  0.0270,\n",
            "          0.1097,  0.0289]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Correct! üéâ"
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Congratulations!** üéâüéâüéâ\n",
        "\n",
        "You've successfully completed the first part of this assignment."
      ],
      "metadata": {
        "id": "WfD_EnZELeiO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2 - Datasets and Data Loaders (~20 min)\n",
        "\n",
        "Now that you've created your first neural network model, let's put it to the test."
      ],
      "metadata": {
        "id": "N_V6IoDHytHG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Doodle to Emoji Demo App\n",
        "Let's say you're working for a mobile messaging company. You've noticed how much time people spend trying to find the right emoji, scrolling endlessly through the options given in the keyboard. Sometimes, even searching for it using keywords doesn't give you what you want!\n",
        "\n",
        "To solve this, you've taken it on your own to create a way for users to just *draw* the emoji they want!\n",
        "\n",
        "**Using a neural network, develop a model that can translate a user-drawn doodle into its corresponding emoji.**\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1XGb5lO0t-vAx7rSs_LUVHngFTbfdlrr8\" width=\"600\">\n",
        "\n",
        "You've been given the user interface below, and your job is to train ```model``` such that it gives accurate results. Currently, ```model``` is just a dummy function, but feel free to try out the interface! (The predictions will just be placeholders).\n",
        "\n",
        "To make things a little simpler, we will focus on emojis for this project.\n",
        "\n",
        "The ten emojis are:\n",
        "\n",
        "- smile üòÑ, eyes üëÄ, car üöó, star ‚≠ê, stop sign üõë, bed üõèÔ∏è, baseball ‚öæ, basketball üèÄ, pizza üçï, bicycle üö≤"
      ],
      "metadata": {
        "id": "vNGjo7iuju3d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: **Run the demo below!**\n",
        "\n",
        "Play around with the tool and try drawing sketches of emojis! Note that because we are only using a placeholder model, all of the predictions will be the same regardless of your sketch üòÄ.\n",
        "\n",
        "To stop the demo, press the stop button on the top left of the cell."
      ],
      "metadata": {
        "id": "MBlhUaTIIgTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(doodle):\n",
        "    if doodle is None: return\n",
        "    doodle = doodle / 255.\n",
        "    y_hats = np.array([0.1]*10)\n",
        "    emoji_names = np.array(list(DOODLE_TO_EMOJI_MAP.values()))\n",
        "    emoji_dict = {emoji_names[i]: float(y_hat) for i, y_hat in enumerate(y_hats)}\n",
        "    return emoji_dict\n",
        "\n",
        "interface = gr.Interface(predict, inputs='sketchpad', outputs='label', theme=\"default\", live=True, description=\"Guess the Doodle!\")\n",
        "interface.launch(debug=True)"
      ],
      "metadata": {
        "id": "n97XzvoL0yrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The rest of this week's project will focus on *training your own model* to predict the correct emoji from a sketch.\n",
        "\n",
        "In order to train a model, we must have data! Now, we will introduce two classes: `Dataset` and `DataLoader`.\n",
        "\n",
        "Remember to stop the previous cell before continuing!"
      ],
      "metadata": {
        "id": "zCNH8oRxIoCp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: The `Dataset` class\n",
        "\n",
        "As you might imagine, loading data is a big part of training a neural network. To make things easier, PyTorch has a whole class defined that just deals with loading data for the neural network.\n",
        "\n",
        "This class is called a [PyTorch Dataset](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html). To create a PyTorch Dataset, just create a class that inherits the `torch.utils.data.Dataset` abstract class. There are a lot of methods that come along for the ride, but the two that you need to override to customize any PyTorch Dataset are:\n",
        "\n",
        "- `__len__` so that `len(dataset)` returns the size of the dataset.\n",
        "- `__getitem__` to support the indexing such that `dataset[i]` can be used to get `i`th sample."
      ],
      "metadata": {
        "id": "rWZVTQKLzkwi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) Create a PyTorch Dataset class using the template provided below.\n",
        "\n",
        "We've included a function, `split()`, which returns three Datasets: a train, validation, and test dataset with the validation and test dataset each containing `pct` percent of the total data and the training data containing the rest."
      ],
      "metadata": {
        "id": "3TFPCtFORvI2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EmojiDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # TODO: Initialize class_names and num_classes instance variables\n",
        "        self.class_names = list(DOODLE_TO_EMOJI_MAP.keys())\n",
        "        self.num_classes = 10\n",
        "\n",
        "        # TODO: Get and set X, Y\n",
        "        self.X = np.load('/content/drive/MyDrive/DLE-Jun23/Projects/dle_utils/emoji_data/emoji_X.npy')\n",
        "        self.Y = np.load('/content/drive/MyDrive/DLE-Jun23/Projects/dle_utils/emoji_data/emoji_y.npy')\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # TODO: Get X[idx]\n",
        "        x = self.X[idx]\n",
        "        # TODO: Normalize image to [0, 1] range\n",
        "        x = x / 255.0\n",
        "        # TODO: Convert datatype to np.float32\n",
        "        x = x.astype(np.float32)\n",
        "        # TODO: Convert x to a Torch tensor object\n",
        "        x = torch.from_numpy(x)\n",
        "        # Get the corresponding label\n",
        "        y = self.Y[idx]\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        # TODO: Return the number of images in X\n",
        "        return len(self.X)\n",
        "\n",
        "    def split(self, pct=0.1):\n",
        "        # Nothing to do here, this function just splits your data\n",
        "        torch.manual_seed(0)\n",
        "        indices = torch.randperm(len(self)).tolist()\n",
        "        n_pct = int(np.floor(len(indices) * pct))\n",
        "        train_ds = torch.utils.data.Subset(self, indices[:-(2*n_pct)])\n",
        "        val_ds = torch.utils.data.Subset(self, indices[-(2*n_pct):-n_pct])\n",
        "        test_ds = torch.utils.data.Subset(self, indices[-n_pct:])\n",
        "        return train_ds, val_ds, test_ds\n"
      ],
      "metadata": {
        "id": "VQO_Fa6uzj1s"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mUyFIVLFfW9"
      },
      "source": [
        "Now use the `EmojiDataset` class to create `train_ds`, `val_ds`, and `test_ds`. Set `pct=0.1`. This will randomly split the entire dataset into 80\\% training, 10\\% validation, and 10\\% testing data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "s1yN_v01-OUI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "outputId": "6c32bd26-ab69-46cd-90dc-897bba6dcbcf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Correct! üéâ"
          },
          "metadata": {},
          "execution_count": 118
        }
      ],
      "source": [
        "# TODO: Instantiate EmojiDataset\n",
        "emoji_dataset = EmojiDataset()\n",
        "# TODO: Partition ds into train_ds, val_ds, test_ds\n",
        "train_ds, val_ds, test_ds = emoji_dataset.split(pct=0.1)\n",
        "check('1.5.1', [train_ds, val_ds, test_ds])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aG2kZxuap7X1"
      },
      "source": [
        "2) Now, using the training dataset, visualize the first 10 doodles and print the class name. A `Dataset` object can be accessed in two ways:\n",
        "\n",
        "- Access a specific index or range of indices, just as you would with a list.\n",
        "- A dataset is `Iterable`, meaning you can use it in a loop:\n",
        "\n",
        "        for data, label in train_ds:\n",
        "          ...\n",
        "\n",
        "**Hint**: You'll have to reshape the image size to `(28,28)`.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "vnh8jxfQO5iu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "outputId": "ee89f197-0a41-4760-ba9a-b7ba2e9d9413"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x400 with 10 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABiEAAACtCAYAAADWI9yPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABH8klEQVR4nO3deZxOdf/H8c+YGPuWfR1L3SISKnfcqCwpRJaKEEKhoqhUVLekUlG0SGW5I2W9yda+EJUlaUUZe9aMLdvM+f1xP8yv8/18NJdrrnPNNbyej0d/fD5951xnZr7X95xzHXPecZ7neQIAAAAAAAAAABBh2TJ7BwAAAAAAAAAAwNmJmxAAAAAAAAAAACAQ3IQAAAAAAAAAAACB4CYEAAAAAAAAAAAIBDchAAAAAAAAAABAILgJAQAAAAAAAAAAAsFNCAAAAAAAAAAAEAhuQgAAAAAAAAAAgEBwEwIAAAAAAAAAAASCmxA4pz322GMSFxcne/bsicrrJSUlSVxcnDz77LOBvs6nn34qcXFxMmPGjIht89TP6q8SExPltttui9hrAAAQ6rE5s49Bp47pEydOzLR9AADAEu3r3DORmJgoLVq0iNj2rOOxde2KYDHnmHOxhOuJ2MRNCCALmzp1qowePTqzdwMAAAAAAAAATOdl9g4ACN/UqVPl+++/l/79+2f2rgAAEFW//PKLZMvGv6cBAAAAcOa4noguftIAgAw7evSopKamZvZu4BzCnENCQoJkz549s3cDCBzrHQAAQORxPRFd5/RNiG3btkn37t2lePHikpCQINWqVZM333xTREQOHTokefLkkXvuuUd93datWyU+Pl5GjBiR1tu/f7/0799fypYtKwkJCVK5cmV5+umnuWDIIvbs2SMdOnSQ/Pnzy/nnny/33HOPHD16NO3/T5gwQa6++mopVqyYJCQkSNWqVeWVV15R21mxYoU0a9ZMihQpIrly5ZIKFSpI9+7d//a1Pc+TXr16SY4cOWTWrFlp/bfeektq164tuXLlksKFC8vNN98sW7ZsSfv/jRo1kvnz58umTZskLi5O4uLiJDEx0bftlJQUeeihh6REiRKSJ08eadWqlW8bIiJffPGFtG/fXsqVKycJCQlStmxZGTBggPz5559n8iNEFrFt2zbp0aOHlCpVShISEqRChQpy5513yvHjx2Xfvn0ycOBAqV69uuTNm1fy588vzZs3lzVr1vi2cSpzZNq0afLII49I6dKlJXfu3HLgwIFM+q4Qy5hzCFd6x2brGa779++XAQMGSGJioiQkJEiZMmWkS5cusmfPnrDO7U63rb/z888/S7t27aRw4cKSM2dOqVOnjsydOzdjPwxkCax3iBauYxGqaF7npqamyujRo6VatWqSM2dOKV68uPTu3Vv++OMPc9/ef/99qVmzpuTMmVOqVq3quxYWkZDXTcQW5hxiCdcTseWcfRzTzp07pW7duhIXFyf9+vWTokWLysKFC6VHjx5y4MAB6d+/v7Rp00beeecdef755yU+Pj7ta99++23xPE86deokIiJHjhyRhg0byrZt26R3795Srlw5+fLLL2Xw4MGyY8cOntmfBXTo0EESExNlxIgRsnz5cnnxxRfljz/+kMmTJ4uIyCuvvCLVqlWTVq1ayXnnnSfz5s2TPn36SGpqqvTt21dERHbt2iVNmzaVokWLyoMPPigFCxaUpKQkdWD7q5SUFOnevbu88847Mnv2bLn++utFRGT48OEyZMgQ6dChg9x+++2ye/duGTNmjDRo0EBWr14tBQsWlIcffliSk5Nl69atMmrUKBERyZs3r2/7w4cPl7i4OHnggQdk165dMnr0aGncuLF8++23kitXLhERmT59uhw5ckTuvPNOOf/88+Xrr7+WMWPGyNatW2X69OkR/1kj82zfvl0uv/xy2b9/v/Tq1UuqVKki27ZtkxkzZsiRI0fkt99+kzlz5kj79u2lQoUKsnPnThk3bpw0bNhQfvzxRylVqpRve8OGDZMcOXLIwIED5dixY5IjR45M+s4Qq5hzyIj0js2uQ4cOyb/+9S/56aefpHv37lKrVi3Zs2ePzJ07V7Zu3So1a9YM+dwuvW0VKVLE3IcffvhB6tWrJ6VLl5YHH3xQ8uTJI++++660bt1aZs6cKW3atIn8DwoxgfUO0cJ1LM5ENK9ze/fuLRMnTpRu3brJ3XffLRs3bpSxY8fK6tWrZenSpb5/bbx+/Xq56aab5I477pCuXbvKhAkTpH379rJo0SJp0qSJiMgZr5uIDcw5xBKuJ2KMd47q0aOHV7JkSW/Pnj2+/s033+wVKFDAO3LkiLd48WJPRLyFCxf6xtSoUcNr2LBhWj1s2DAvT5483rp163zjHnzwQS8+Pt7bvHlzYN8HMubRRx/1RMRr1aqVr9+nTx9PRLw1a9Z4nud5R44cUV/brFkzr2LFimn17NmzPRHxvvnmm9O+3saNGz0R8UaOHOmdOHHCu+mmm7xcuXJ5ixcvThuTlJTkxcfHe8OHD/d97dq1a73zzjvP17/++uu98uXLq9f55JNPPBHxSpcu7R04cCCt/+6773oi4r3wwgtpPet7GzFihBcXF+dt2rQprXfqZ/VX5cuX97p27Xra7xexpUuXLl62bNnMOZqamuodPXrUS0lJ8fU3btzoJSQkeP/+97/TeqfmV8WKFc35A5zCnEM4Qj02u8egoUOHeiLizZo1S20zNTXV8zwv5HO7ULZ16pg+YcKEtP93zTXXeNWrV/eOHj3qG3/llVd6F1xwQWg/AGRJrHeIFq5jEYpoX+d+8cUXnoh4U6ZM8fUXLVqk+uXLl/dExJs5c2ZaLzk52StZsqR36aWXpvVCXTet47F17YpgMeeYc7GE64nYdE4+jsnzPJk5c6a0bNlSPM+TPXv2pP3XrFkzSU5OllWrVknjxo2lVKlSMmXKlLSv/f777+W7776TW2+9Na03ffp0+de//iWFChXybatx48aSkpIin3/+eWZ8mzgDp+64n3LXXXeJiMiCBQtERNL+akBEJDk5Wfbs2SMNGzaU3377TZKTk0VEpGDBgiIi8t5778mJEyf+9vWOHz8u7du3l/fee08WLFggTZs2Tft/s2bNktTUVOnQoYNvPpUoUUIuuOAC+eSTT0L+vrp06SL58uVLq9u1ayclS5ZM+77c7+3w4cOyZ88eufLKK8XzPFm9enXIr4XYlpqaKnPmzJGWLVtKnTp11P+Pi4uThISEtFCmlJQU2bt3r+TNm1f+8Y9/yKpVq9TXdO3a1Td/gL9iziGj0js2u2bOnCmXXHKJ+a+D4uLiRERCPrcLZVuuffv2yccffywdOnSQgwcPph2/9+7dK82aNZP169fLtm3b0vmukRWx3iFauI7FmYrWde706dOlQIEC0qRJE99cql27tuTNm1ddw5YqVcp3jM2fP7906dJFVq9eLb///ruIyBmvm4gNzDnEEq4nYss5+Tim3bt3y/79++W1116T1157zRyza9cuyZYtm3Tq1EleeeUVOXLkiOTOnVumTJkiOXPmlPbt26eNXb9+vXz33XdStGjR024Lse2CCy7w1ZUqVZJs2bJJUlKSiIgsXbpUHn30UVm2bJkcOXLENzY5OVkKFCggDRs2lLZt28rjjz8uo0aNkkaNGknr1q2lY8eOkpCQ4PuaESNGyKFDh2ThwoXSqFEj3/9bv369eJ6n9umUMwnNcbcRFxcnlStXTvu+REQ2b94sQ4cOlblz56pnJ546CUDWt3v3bjlw4IBcfPHFpx2TmpoqL7zwgrz88suyceNGSUlJSft/559/vhpfoUKFQPYVZwfmHDIqvWOz69dff5W2bdv+7TZDPbcLZVuuDRs2iOd5MmTIEBkyZIg5ZteuXVK6dOkz2i5iH+sdooXrWJypaF3nrl+/XpKTk6VYsWLmfrhzqXLlyupDuAsvvFBERJKSkqREiRJnvG4iNjDnEEu4nogt5+RNiFMhW7feeqt07drVHFOjRg0R+d+/JB85cqTMmTNHbrnlFpk6daq0aNFCChQo4NtekyZN5P777ze3dWphQ9bx14PTr7/+Ktdcc41UqVJFnn/+eSlbtqzkyJFDFixYIKNGjUqbT3FxcTJjxgxZvny5zJs3TxYvXizdu3eX5557TpYvX+7La2jWrJksWrRInnnmGWnUqJHkzJkz7f+lpqZKXFycLFy40Pd8uVPc3IeMSElJkSZNmsi+ffvkgQcekCpVqkiePHlk27ZtcttttxFId4558sknZciQIdK9e3cZNmyYFC5cWLJlyyb9+/c35wL/QhMZxZzDmTjdvxg6U6Gc24Xj1JwdOHCgNGvWzBxTuXLlDL0Gsi7WO0QC17HIqKCuc1NTU6VYsWK+fxn8V6e70fV3znTdRGxiziGWcD2Ruc7JmxBFixaVfPnySUpKijRu3Phvx1588cVy6aWXypQpU6RMmTKyefNmGTNmjG9MpUqV5NChQ+luC7Fr/fr1vn9xtmHDBklNTZXExESZN2+eHDt2TObOnSvlypVLG3O6xyLVrVtX6tatK8OHD5epU6dKp06dZNq0aXL77bf7xtxxxx3SokULad++vcyePVvOO+9/b8dKlSqJ53lSoUKFdE/801tA169f76s9z5MNGzakXZysXbtW1q1bJ5MmTZIuXbqkjfvggw/+drvIeooWLSr58+eX77///rRjZsyYIVdddZW88cYbvv7+/ftPG5oEnA5zDhn1d8dmS6VKlf52vp0S6rldKNv6q4oVK4rI//5ikXPCcwvrHaKF61icqWhd51aqVEk+/PBDqVevXkg3UU/9a9+/Xs+uW7dORCTtOM+6mTUx5xBLuJ6ILedkJkR8fLy0bdtWZs6caU6I3bt3++rOnTvL+++/L6NHj5bzzz9fmjdv7vv/HTp0kGXLlsnixYvVtvbv3y8nT56M7DeAiHvppZd89anFo3nz5ml/jeB5Xtr/T05OlgkTJvi+5o8//vCNERGpWbOmiIgcO3ZMvWbjxo1l2rRpsmjRIuncuXPaHc8bb7xR4uPj5fHHH1fb8zxP9u7dm1bnyZPnbx+ZNHnyZDl48GBaPWPGDNmxY0faHLa+N8/z5IUXXjjtNpE1ZcuWTVq3bi3z5s2TFStWqP/veZ7Ex8erOTd9+vQs/cxBZB7mHDLq747NlrZt28qaNWtk9uzZ6v+58yy9c7sz2dYpxYoVk0aNGsm4ceNkx44d6v+755c4e7DeIVq4jsWZitZ1bocOHSQlJUWGDRum9uHkyZOyf/9+X2/79u2+Y+yBAwdk8uTJUrNmTSlRooSICOtmFsWcQyzheiK2nJN/CSEi8tRTT8knn3wiV1xxhfTs2VOqVq0q+/btk1WrVsmHH34o+/btSxvbsWNHuf/++2X27Nly5513qmfyDxo0SObOnSstWrSQ2267TWrXri2HDx+WtWvXyowZMyQpKYm7pjFu48aN0qpVK7n22mtl2bJl8tZbb0nHjh3lkksukZw5c0qOHDmkZcuW0rt3bzl06JCMHz9eihUr5lsUJk2aJC+//LK0adNGKlWqJAcPHpTx48dL/vz55brrrjNft3Xr1jJhwgTp0qWL5M+fX8aNGyeVKlWSJ554QgYPHixJSUnSunVryZcvn2zcuFFmz54tvXr1koEDB4qISO3ateWdd96Re++9Vy677DLJmzevtGzZMm37hQsXlvr160u3bt1k586dMnr0aKlcubL07NlTRESqVKkilSpVkoEDB8q2bdskf/78MnPmTJUNgbPDk08+Ke+//740bNhQevXqJRdddJHs2LFDpk+fLkuWLJEWLVrIv//9b+nWrZtceeWVsnbtWpkyZUra3XjgTDHnkBF/d2y2DBo0SGbMmCHt27eX7t27S+3atWXfvn0yd+5cefXVV31fF8q5Xajb+quXXnpJ6tevL9WrV5eePXtKxYoVZefOnbJs2TLZunWrrFmzJnI/IMQU1jtEC9exOBPRus5t2LCh9O7dW0aMGCHffvutNG3aVLJnzy7r16+X6dOnywsvvCDt2rVL2+aFF14oPXr0kG+++UaKFy8ub775puzcudP3YTTrZtbEnEMs4XoixnjnsJ07d3p9+/b1ypYt62XPnt0rUaKEd80113ivvfaaGnvdddd5IuJ9+eWX5rYOHjzoDR482KtcubKXI0cOr0iRIt6VV17pPfvss97x48eD/lYQpkcffdQTEe/HH3/02rVr5+XLl88rVKiQ169fP+/PP/9MGzd37lyvRo0aXs6cOb3ExETv6aef9t58801PRLyNGzd6nud5q1at8m655RavXLlyXkJCglesWDGvRYsW3ooVK9K2s3HjRk9EvJEjR/r24+WXX/ZExBs4cGBab+bMmV79+vW9PHnyeHny5PGqVKni9e3b1/vll1/Sxhw6dMjr2LGjV7BgQU9EvPLly3ue53mffPKJJyLe22+/7Q0ePNgrVqyYlytXLu/666/3Nm3a5HvtH3/80WvcuLGXN29er0iRIl7Pnj29NWvWeCLiTZgwQf2s/qp8+fJe165dw/nRI5Ns2rTJ69Kli1e0aFEvISHBq1ixote3b1/v2LFj3tGjR7377rvPK1mypJcrVy6vXr163rJly7yGDRt6DRs2TNvGqfk1ffr0zPtGkGUw53CmQj02W8egvXv3ev369fNKly7t5ciRwytTpozXtWtXb8+ePep10ju3S29bp47pfz1Wep7n/frrr16XLl28EiVKeNmzZ/dKly7ttWjRwpsxY0bGfjCIeax3iBauY5GeaF/nnvLaa695tWvX9nLlyuXly5fPq169unf//fd727dvTxtTvnx57/rrr/cWL17s1ahRw0tISPCqVKmi1r1Q103reGxduyJYzDnmXCzheiI2xXneaf4GBD5t2rSRtWvXyoYNGzJ7VwAAAJBBnNsBOBew1gEAEAyOsWfmnMyEOFM7duyQ+fPnS+fOnTN7VwAAAJBBnNsBOBew1gEAEAyOsWfunM2ECMXGjRtl6dKl8vrrr0v27Nmld+/emb1LAAAACBPndgDOBax1AAAEg2Ns+PhLiL/x2WefSefOnWXjxo0yadIkKVGiRGbvEgAAAMLEuR2AcwFrHQAAweAYGz4yIQAAAAAAAAAAQCD4SwgAAAAAAAAAABAIbkIAAAAAAAAAAIBAhBRMnZqaKtu3b5d8+fJJXFxc0PuEGOZ5nhw8eFBKlSol2bIFew+LeYdTojXvmHP4K+Ydoo1jLDIDax2ijbUOmYG1DpmBeYdo4xiLzBDqvAvpJsT27dulbNmyEds5ZH1btmyRMmXKBPoazDu4gp53zDlYmHeINo6xyAysdYg21jpkBtY6ZAbmHaKNYywyQ3rzLqTbYvny5YvYDuHsEI05wbyDK+g5wZyDhXmHaOMYi8zAWodoY61DZmCtQ2Zg3iHaOMYiM6Q3J0K6CcGf1cAVjTnBvIMr6DnBnIOFeYdo4xiLzMBah2hjrUNmYK1DZmDeIdo4xiIzpDcnCKYGAAAAAAAAAACBCCkTAgAAAAAAAAhFjhw5VK9evXq+ukqVKmpM3rx5VW/BggWq98MPP2Rg7wAA0cZfQgAAAAAAAAAAgEBwEwIAAAAAAAAAAASCmxAAAAAAAAAAACAQZEIAAAAAAABAyZUrl+p17NjRV7do0UKNady4sepZeQ+hGD58uOqVLl3aV+/evTusbePcExcXp3oVK1ZUvaSkJNVLSUkJYpeAcwJ/CQEAAAAAAAAAAALBTQgAAAAAAAAAABAIbkIAAAAAAAAAAIBAcBMCAAAAAAAAAAAEgmBqICCJiYmq17RpU9VzA5AKFSoU1utlz55d9dauXat633zzjep99dVXvvrEiRNh7QMAAAAAIPYlJCSoXq9evVRv8ODBqleyZElfvW7dOjVm/PjxqrdgwQJfvWrVKjXm5MmTqle3bl3VI4j67GYFRbufp1xzzTVqjBtYLiJSsGBBX120aFE1pkiRIqq3detW1Zs4caKvfuONN9QYK9AaAH8JAQAAAAAAAAAAAsJNCAAAAAAAAAAAEAhuQgAAAAAAAAAAgEBwEwIAAAAAAAAAAASCYGogDHXq1PHVH3zwgRpToEAB1YuLi1O9/fv3++o///xTjbF6LiuYulu3bul+nYjInj17fPXrr7+uxjzyyCOql5KSEtL2AQAAAPw/99y9atWqaswPP/ygelZoLxCKdu3a+ernn39ejSlbtqzqLVq0SPVat27tq7/++uuM7Vw63n///UC3j+ixQsZHjhypevXr1093W7/88ovqHThwQPUuuugiX+15nhozZMgQ1atVq5bqPfDAA776oYceUmPcAHYRkUGDBvnqn3/+WY0Bznb8JQQAAAAAAAAAAAgENyEAAAAAAAAAAEAguAkBAAAAAAAAAAACwU0IAAAAAAAAAAAQCIKpgb8oVKiQ6o0dO1b1br75Zl9tBcRZvcsvv1z1vv322zPYwzNTsGBB1bOCoB599FFf/eCDD6oxVvD1/fff76tTU1PPcA8BAACAc0+3bt189bhx49SYu+++W/XGjBkT2D4ha4qPj1e9p556SvXuu+8+X7106VI15pZbblE9a1xCQoKvnjdvnhpjhfOOHz/eV1vXzBdeeKHquWHAIiL9+vXz1X/++acag+iy5uLDDz/sq4cOHarGbNmyRfX69Omjeu6c2rRpkxqTN29e1bvtttt89bJly9SYlStXql6rVq1Ur3r16r66UqVKaswVV1yhem7Ae+3atdWYvXv3qh5wNuEvIQAAAAAAAAAAQCC4CQEAAAAAAAAAAALBTQgAAAAAAAAAABAIMiFwTqtSpYqvnjt3rhpTunRp1Xvsscd89ZIlS9SYjz/+WPVKlChxhnuYMfv371c96/upUaOGrz548KAa4z5DVEQ/r7NTp05qjLUtAAAyonDhwqq3b9++TNgTAAjPqlWr0h0TFxcXhT35f7ly5VK9evXqqd6HH34Yjd3BaeTLl89Xz549W425+uqrVe+5557z1VYOYEpKSkj7EMq4l19+WfXc5/w//vjjaoyVZ+FmUIjY+QOInlKlSqneW2+9pXpXXXWVr37ttdfUmP79+6teuBkfhw4dUj035zNbNv3vsadPn6567dq1U701a9b46iZNmqgxO3fuVL2vvvrKV0+ePFmNadmypeqRu+lnZXB88803qudmoa5bty6wfULo+EsIAAAAAAAAAAAQCG5CAAAAAAAAAACAQHATAgAAAAAAAAAABIKbEAAAAAAAAAAAIBAEU/+N3Llzq17RokVVL2fOnL76xIkTaowV3LR3717Vs0J0EBk1a9ZUvU8++cRXWz//Bg0aqN7KlSt9dYECBULaBzfIWURk0aJFIX1tOKww6WeffVb13nvvPV/drVs3NcYKSXrllVd89eeff67GWD8/wqozrkyZMqrXrFkz1StXrpzqJSYmpjvG8zzV+/bbb3316tWr1RgrqHDHjh2qh8goW7as6mXPnj3drzt+/Ljq/fHHH6rnhv+WL19ejVmyZEm6rwdkxAMPPKB6VpBloUKFVC/cUEMgSDly5FC9ChUq+GrrnNG95sgIK+hy8eLFvjrU6xLr+sgNig817PZc4p6nJycnqzGTJk2K1u6IiMjgwYND6lnXPkeOHAlkn6DNmzfPV9evX1+NeeONN1TPvXbLyPvy5MmTvtq6VmzevLnqPf/8877aCgN2ty1iBwTz2Ul0XXHFFb7anYci9vHtpptu8tXvvvtu2PsQFxfnq9u3b6/GHDt2TPWSkpJ8tTU3rTk2cOBA1Rs1apSvDjU4um/fvr56woQJaowV2n3HHXeonvUeOVeUKFFC9axrgJIlS/rqoIOpraB293O2iy66SI3p3Lmz6s2YMSNyOxZj+EsIAAAAAAAAAAAQCG5CAAAAAAAAAACAQHATAgAAAAAAAAAABIKbEAAAAAAAAAAAIBBnXTB1nTp1VK9t27aq16JFC9WrWLGir7aCqSPJCn5dvny5r7aCmqyQki1btkRux84C+fLlU72ZM2eqnhuaZ4V6hRKqawXJ7dq1S/UuuOCCdLcVrkqVKqnesGHDVO/tt99WvU6dOvlqa25awUm//fabr37//ffVGCsUrUOHDqqH/+euRSI6FLBLly5qjBUEdvToUdXbvHnz39YiIuedpw8P3bt399VWKKH1em4InojIU0895aut9wv8rGNZ0KFVbtCatTasX79e9ayQa7fnrr8iIvv371c9d1wo2z5db82aNb56z549aszhw4dVD9HlnstZx7LJkyerXlYOob7nnntU78cff/TVH3zwQbR2ByFKTExUvRtuuMFXW2GtDRo0UL3s2bNHbL/C9cQTT/jqa6+9Vo1xQ0FF7KDF/v37++rx48dnbOeyuCpVqqieG6jq/vxF7GuMSHLn54ABA9QYK0SWEOrosdaQhg0b+mrr/Pv2229Xvdtuu81Xv/7662rMgw8+qHrhzsOFCxeqXnx8vK+2wo2t78eah2PGjPHVDz/8sBpjhRQjfdZ15Zdffumrrd/TJZdconobNmyI2H4VLlzYV0+aNEmNyZkzZ7rbsa5prM8ynnvuuTPYu783ceJEX+0GJ4uIDB8+XPWKFCmiem3atPHV1vdztrJCqC29evXy1Z999lnE9iFv3ryqN3/+fNWrXLmyr7bmphW0fTbjLyEAAAAAAAAAAEAguAkBAAAAAAAAAAACwU0IAAAAAAAAAAAQiJjNhHCfFShiPwP9kUce8dXWs9StZ9VZz9WdM2eOr7aeFW31jh8/rnouK1/CevaX+xxZ6xl0Vm/ZsmW++tlnn1VjZs+ene5+ni0GDhyoeuXLl1e9unXr+upQ8h9CtW7dOtW78MILI7Z9V58+fVTv5MmTqmc9dzrcZwi6z9W799571ZixY8eqnvucYBGR0aNHh7UPWY37LOW7775bjRkxYoTqpaSk+Gr3Gagi9s86KSnpDPfw9Nx9r1atmhpjzcO+ffuqXs+ePdP9uv/85z9nuotntUaNGqne3r17Ve/OO+9Md1vW8yit52v269fPV1vPv/z6669D2pbbs56lHsrXhfKc14z44osvVM/N3liwYIEaE8nn3Z5LrGwZ97nP1jpmPbc8K7vvvvtUz31ONpkQkWFlGtSuXdtXu+fjIiKtWrVSvRo1aqiee061atUqNcY6zv/888++2noGtHUcsM4t3feVtXbnyZNH9dzrKutZ6h999JHqrVy5UvXeeecd1TtXWHPMOkdzs4teeOGFwPZJxF5nnn76aV/tPvNdROSuu+4KbJ/gl5CQoHrjxo1Tva+++spXW7mG1vPm3XNy65rMWlOsfJgTJ06oXijc3Abrmvlf//qX6g0ZMkT13P2/+OKL1Zgbb7xR9cg0SV/Hjh1VL1s2/79hzpUrlxrz5JNPqt6tt97qq0P5/Ox03GufYsWKqTHlypVTvccee8xXt2vXTo1p2rSp6lnXBe5c/PTTT61dTZd1LnDgwAHVs44fblbM3Llzw9qHrMjKT7KuR63Mm0ix1qiaNWuqnnsNY52PZeVMu3DwlxAAAAAAAAAAACAQ3IQAAAAAAAAAAACB4CYEAAAAAAAAAAAIBDchAAAAAAAAAABAIGImmNoNdnvjjTfUmDp16qieG4z70EMPqTFWgOTBgwdVzw2CKlq0qBqzdetW1XMDbKyv+/3331Vv0aJFqueGg1mhOm3btlU9N7R71qxZasyrr76qelaQcFYLRildurTqDRo0SPUWLlyoevv27fPVhQsXVmP279+veqmpqenu1+bNm1XPCjCMlEqVKqneTz/9pHq7d+8ObB9eeukl1bvyyitV75lnnlG9JUuW+OoVK1ZEbscyyXnn6SV2ypQpvrpDhw5qzPTp01XPDZIL8vd4Om7AnRUAFR8fH9K23Pfem2++me4YEZH58+eHtP2z0fnnn69627dvVz1r/oSrR48evvrbb79VY7p27Rqx1wuFFYJnBVpboa7t27f31W4Iq4hImTJlVG/06NG+2goPtYKp//vf/6qeG8hoBb/GuubNm6ueFSzZoEEDX20FW1ohkuXLl/fV11xzjRpjncfFKvf89eqrr1Zjihcvrnr58+cPbJ/OBtYxtkmTJr7aCph2wxxFREqVKuWrrfflJ598onpTp05VPTc00wp5teaAe+5qrXW7du1SPff8ydoH6/1i9dywVut82goBtYJfs+LaFiluCKuIvY7ddtttvtoNqj4T7nWsFWR6++23q96kSZN8de/evdWYc/l3GW1XXXWV6lkB0507d/bVJ0+eVGO2bNmieg8++KCvtkLl3333XdVz56qIyPjx41XPVbBgQdWrW7eurx44cKAaY611VkD60qVLffXkyZPVGOszlxYtWvhqKwz4XGL9ntzPpUREPv74Y19tXXNYnwfky5fPV1ufZ4UbFm4dy3744QfVq1ixoq/+/PPP1ZiJEyeqnnveLqJDoAsUKKDGeJ6neqGYMGGC6lnrufXZz9mqcuXKvvqSSy5RY7755hvVcz9nadasmRqTnJyseocOHUq3lzt3bjXGmsOJiYm+2voM5+eff1a9sxl/CQEAAAAAAAAAAALBTQgAAAAAAAAAABAIbkIAAAAAAAAAAIBAcBMCAAAAAAAAAAAEIlOCqQcPHqx6jz/+uK/euXOnGmOFy7mhMKGyAp7cwE0reO29995TPTfYKFRWeMrll1/uq61w41GjRqneiy++6KuHDBmixlgBnG7Ii4gO2g43VCdaRo4cqXpWmJ/1ewr3d+eGV1nh1W4Ak4gOjRPRwaXWtqyeG9pbq1YtNcYKJHPDwER0uK0VBnb06FHVC4UVft6xY0fVcwOss1owtRWQaQVWtmvXzlf36dNHjXnllVcit2MR9Oijj/pq6332n//8R/UaNmyoeuXKlfPVq1atUmOmTZumem6woxWOfbZwg6zcUGURO4jwtddeU71t27b5aivQ2uqVLVvWV1vBrNH2559/htQL5fuxtG7dWvX27Nnjq61gZve9LSJy3333qd6cOXN8tRUqG+uefPJJ1XODfUV0sHLOnDnDej03OFVE5KabblK95cuXh7X9cFlr4JgxY1SvW7duvjpbttD+DZB73mudP1vHmU2bNoW0/VhRv359X/3YY4+pMdb8ctdIEf07OXHihBrjvp9FRL777jtf7QY7i4hUqVJF9aywdZcVcGid47jnXjly5FBjrLXOChR13zPhXi+tWbNG9RYsWKB6VoBp//79w3rNrKhw4cK++tlnn1VjrBDUefPm+erRo0erMdY6Y60h1113na8uUaKEGmOtIU899ZTqIfO0bNlS9azrQGs+hcMKFrbOybt06aJ6oQRTW+epLmudDpV7rXD48GE1xgra/uijj3y1tZZbx4Gz1bBhw1TPXddERO655x5f/f3336sxVtCvGxhuzZ1OnTqlu5+hsj5zufTSS331Qw89pMZYodDWta37OWEkPy+zfu4W61zmbGV9DuyyzoXc46L1+VyhQoXC3q9wuJ95iYhs2LAhqvuQ2fhLCAAAAAAAAAAAEAhuQgAAAAAAAAAAgEBwEwIAAAAAAAAAAASCmxAAAAAAAAAAACAQgQdTDx06VPXcEGoRkYkTJ/pqK8zMCrkJlxXCZQVRu6wg4xdeeMFXW8HR77zzjuqFG9BoSUlJ8dVWqN/GjRtVz/25i4i0atXKV7vBybGmatWqqvfll1+qnjXv3AAbK9DGCqsJ5eusgKsiRYqonjvvLrzwwnRfT0Tk/PPP99XZs2dXY6wQ1mXLlqleKKxQtJ9++slXWwGr1ryzZLUgTZcV/G4F1d5xxx2+2goRjlVlypRJd8ygQYNULz4+XvXcoOS33npLjenVq5fqvffee776n//8pxrz66+/prufWYEb5meFn6empqqetfYUL17cV1uBp6EI9f0cLmsd+/HHH331li1b1BjrGOvOFZHQwt4qVaqkekePHvXVVsihFdptzcVQwrFjnRX6XbNmTdVzAwutIOE8efKonhuiW716dTVm3LhxqlerVi3Vc8+PwmWtY1YotHWeOHz4cF994MABNWbkyJGq566TVnCkdZ5thXaHG0wcDcePH/fVVnDgRRddpHrW79YNd/7ll1/UmGPHjp3pLoqIHQT7zDPPqJ57nmUFd1phrfPnz/fVTZo0UWOs0Ewr5HDGjBm++rLLLlNjrNBp1+LFi1XPWm+tMN1zKZjanQfWtYMVKr58+XJfXblyZTUmLi4ug3v3/6w1xL3u69ixoxqTlJQUsX3A32vevLnqWe/DjIQ5p8ddi0RCO7+31uRQ1lsrRDhcbti7iH1cnjNnjq+2rkOs38XZwDpfu/POO1Xv+eefVz3reOZ6++23Vc+9DrE+L7M+oxg7dmy6r2fJlk3/W2t3LQ31XMA6XlvnwZFSunTpkMbt3r07sH2INY0bN/bV3333nRpzySWXROz18ubNm27PGtOsWTPVc99HH330kRrToUMH1fvqq6/S3c+sir+EAAAAAAAAAAAAgeAmBAAAAAAAAAAACAQ3IQAAAAAAAAAAQCAimglx1113qZ71HP5XXnlF9fr06RPJXUnXLbfconru8+vcZ9SKiDRo0ED1BgwY4Kuvv/56NcZ6Fqv1HN8gffbZZyGNi/XnVZcsWdJXW89/s+bi+++/H9g+WaznuFnPU7/66qvD2n7u3Ll99eHDh9WYp59+WvU++OAD1XN/pkWLFlVjrOcTuj9763mS1vPyLFkpE6JcuXKqd//996vepEmTVC8rZUC4Nm/enO6YCy64QPWsrJAdO3b4aut531a2gfu+mjx5shrzr3/9S/Ws7IRYF0pukDXv3JwiS4kSJULquc9wtZ6JHkn/+Mc/VM99Rrb1c3n11VdVz3rufijPKJ81a1a6YyxubsTp1KhRw1dbz86NJdaz3q+77jrVW7t2req5GUfWc58PHTqkej169PDV1rmX9XuyxllZHeGwnv3funVr1evZs6fqvf76677ayh2xMiEeffRRX22tpdb8mTlzpurVqVPHV4eSBxAtX3/9ta+2rgmWLl2qetZ8cnNfateurcZY64Wb27Fv3z57ZwPk5t9cc801asz48eNVz5oD7rxv06aNGhPuHNi6davqna3PTrdYmSvdu3f31dY5ufUcdvfazMrbsNbIcFnHT/fc3XqvWccBK/cikvkVobAyCNycDSuLI5ZZnz94nhfVfXAz/0TsuePmPFk5WFZ2hft7i2ROpsV6BvvAgQN9tXVcsM4pgj4PDoL7vnz55ZfVGDdPSUTkiSeeiNg+uMepe++9V4156KGHVC/cTIiszMp5staAlStXRmN3os7KimvUqJGvtvJKwmXlkFnnWu551ZQpU9SYl156SfW++OILXz1t2jQ1xvp8zvocxMq9zYr4SwgAAAAAAAAAABAIbkIAAAAAAAAAAIBAcBMCAAAAAAAAAAAEgpsQAAAAAAAAAAAgEBkKpnbDMkaPHq3GTJ8+XfX69euXkZeNiO3bt6ueG6pmheNYAYduCGivXr3UGCvkK5KBKqG47777VM8K67J+Z7HECutxbdmyRfWssLRIBX1Z+3T55ZerXiQD2K1wZNeKFStUzwrnipTzztNLihusKSLyyCOPqF5SUlIQuxSIQYMGqZ4VjmetIS43RFNEJEeOHKr3+++/h7h3wXEDE++44w41xgox++WXX1TP/Xm5Acgidli5Gzr/7rvvqjFWQLoVFBXrypcvn+4YN4AxVNZ8ioU5Vr169XTHWGGtc+bMUT3rveWGxVvH5lBCu4sVK6bGVK1aVfWsubhhwwbVi2VWeODu3btVzw2NFwnt92mFsbVq1cpXHzlyJN3tiIgULFgwpHGhqFKliq++++671RjrvNcNobYUKFAgpH1ITk721da5680336x61rjLLrvMV8dSMLXLOjezQqitNatu3bq+evDgwWqM9bt0j7vusSYaxowZ46vd94GIyLJly1TPen+sX7/eV1tBpOGyQrutOR0fH++rrfOkWHfJJZeo3sSJE1XPDRO25mbjxo1Vzz3PadKkiRrTunVr1Vu4cKHqvffee6oXCjdc0w3LPt22S5YsGdbrBc29DrcCRmPZqlWrVK9WrVpR3QcrmNpy0UUX+WormNpy7NgxX21d9wTtzTff9NXu5zki9vlmVgymdteef/7zn2pMx44dVe/AgQOq517rW+G51113nep17tzZV2fPnl2NGTVqlOqFy51jIiKbN2/21TfddJMaY82D1NTUiO1XKKzfz7p161TPOhfPaqzP56zzWje83v1dioj06NFD9dzQafc6UETk5MmTqleqVCnVc8Prn376aTVm8uTJqueefzVs2FCN+fDDD1Vv8eLFqteiRQtfbR2vswL+EgIAAAAAAAAAAASCmxAAAAAAAAAAACAQ3IQAAAAAAAAAAACB4CYEAAAAAAAAAAAIRIaCqd3QrT179qgxVmiVG1QmEv3Al3r16qnetGnTfHWoIW4HDx701VOnTlVjrBA8KxQ6UqxQ5Ntvv131rADFnTt3BrJPkVK5cuV0x1ghpdb35YY0W6EwVpCzG4bz2GOPqTE7duxQPSvMLlyhhHgdPnw4Yq8XCivYxwqTtIKu9u/fH8QuRYT7s+7UqZMaYwW6W3PADZ60wp2tgG93/nbr1k2NsYIKI+nTTz/11XPnzlVjrBDHSy+9VPVy5crlq61gqkKFCqme+3O23usjRoxQPWtfrQD7WBJK+Hy0vwdrn6zg4htuuEH1Dh065Kuff/55NcZa391j5datW9WYCy64QPXcY7qIDhm84oor1JgVK1aonhWA7urSpYvqWcHU7vso1uTOndtXX3nllWqMtYa3bds2rNdr06ZNSL1Q1K9fX/Vmz54d1raGDRvmq92QaBGRxx9/PKxthxpMHcpx0V1LTydbtqzz747cUOXTsQKs3Z/Z22+/rcZYx/BY+Pm455ZuyLaIyIABA1TPmvfdu3f31bt27Qprn6zzkTx58qiedQx3g+L37t0b1j5kpsKFC6uetf7lzZvXV7ds2VKNcUOoRfTP7cknn1RjrFDiPn36qN5DDz3kq61zIcuGDRt8tRXWah23rPfWc889F9JrRooVdv7DDz9EdR8ibfXq1apn/U7cwFX384iMsEJwrc9q3GDqUMPRjx496qvd0NloOHHihK+2vmf3+8uqateu7autY+eMGTNC2pYbMO0GfIvY5y7uevHEE0+oMVbYcLis+dq/f39fPWvWLDXmnnvuUb1IBmaHwjqmL1iwIKr7EIQ6deqo3htvvKF6NWrUSHdbbkh0qB544IGQXq9BgwaqV7NmTV/dt29fNcYKx+7Xr5+vtt5r1jWUNT/nzZvnq5s2barGWMcQK6g9M2X+GTcAAAAAAAAAADgrcRMCAAAAAAAAAAAEgpsQAAAAAAAAAAAgEBnKhPj22299tfVcLOs56dbznN966y1fbT1fLpLPeNy2bZvqXXXVVb764osvDmlbP//8s692n3MYDWXLlvXV1nPSrWeRDh06NKhdCszx48fTHeM+r1BEpGHDhqrXuHFjX92xY8eQ9iGUZ1laz5YcN26c6rlzcfv27WqM9Z6xntPrCvW500Gynmn8008/ZcKehM9dG6ysAisTp1q1aqrnrpPz589XY6699lrVK168uK+2nnNuPWvx+++/V71IsZ6H/sUXX6ie9cxy9z1kPT/5448/Vj03z+euu+5SY6xjhZXxY71mLAnlGbnWc7gjyT22fPfdd2qMlfNkPbvUfR9ZWTrWc9nd5/Za27bWQ/fZnSIit956q+q5rGOM+5785JNP1Bj3mbsiIn/88Yfq/fbbb+nuQ2Zyn0Vr5Q+1a9dO9apXr656bgZOKK8nIrJx40ZfbeWO3Hfffapnzc9wufv1zjvvqDHhZhm5uRunE8oz9AcNGqR61nPSrVycWGU929zqWblzofxOrPdgqM/PjyYrh8R6NrV1zZQ/f35f3ahRIzXGysdzn4NsZcK4+Qci9jOII/mM+sxiPSu6WLFiqudmcLjXhqfj5idZ53GfffaZ6lnXGG6ehPVM9KeffjrdfVqyZInqPfPMM6o3ePBg1du9e7evtp6vjr9n/b6tcyM3O2ny5MkR24cjR46onvV+LlKkSFjbdzPCSpUqFdZ2Ism6Nq1atWom7EnkWefpLvdc+3TcLBJLYmKi6lnHs2hzr52tHFcr18b62YwdOzYi+2QdY6xzG2tdiHXu9YP1mYe1rljHFjd39Ouvv1ZjrHl3/vnn+2orj9A6z/nvf/+reu5n3z179lRjrHPy3r17+2rr+te6hnS/TkTkpZde8tXWz9TN4xLRP2f3Out0vV9//TXdfUhKSlJj0sNfQgAAAAAAAAAAgEBwEwIAAAAAAAAAAASCmxAAAAAAAAAAACAQ3IQAAAAAAAAAAACByFAwtWvGjBmqZ4UBWyEed955p6+2QgiXL1+uem6gtRWKaoWUWqF9buCJGz4SK6ywGjc8JSEhQY1p0aKF6lmhmbEulOBvK6TFnSuWSpUqqd5DDz2ket26dfPVv//+uxpj9S6//HLVc4NfQw2sDIUVuGQF8rhh2KGGY+/YscNXHzt2TI2xQkf79++verHMCvhxuWuYiEizZs1Uzw0GuvDCC9WYzZs3q54bhOh5nhoza9Ys1evXr5/quUHR1pyzgsfcOe2+D0TsOWBt3117rPBqK+jWPc5YQV1WoHXr1q1Vz52Ho0ePVmMy08KFC3219TufOHGi6m3atEn13JDSK664Qo2xgqXc36cVdm/9nsqUKaN6zZs399V58uRRY6xQWXfeuSFjp3PxxRer3siRI321FdK5a9cu1bPmlMsKrvv0009Vz/o9xpKLLroo3THWHLPOARctWuSrrSDcm2++WfXcULqbbrpJjbHCU8MN5rSCzd011zoGhuuDDz5QvaZNm6qeGwjnzl8RkTvuuEP1nnjiCdWzzkmykjVr1qieFZo+bdo0X22ta1awfCiB1tY8sa5zihYt6qut8FYrKPqaa67x1aGce2SEe90jIrJq1SpfPW7cODXGOu4uXrxY9Y4fP56BvYu+ypUrq551jLBC6idMmBDWa1aoUCHdMda17dChQ1XPXbut675QgqktViD6gw8+qHruNf7SpUvVmHfffTesfThXWIGr7vtSROTuu+/21ZEMprZYn51YgdmhcK9XrGsoK+DVuj6NlJ07d6re1VdfHdjrRdO+fft8dVxcnBpjHaf27NkT1utZcyUW3Xbbbapn/WzGjBmjeu511LPPPqvGWOctoeyDFQw/d+7cdLcVa2644QZf7Z5Xi4i0b99e9T7//POwXs/6OvezPetzsOLFi4f1ehbrXNI97lrnS9OnT1e99957T/WsIG+XNRcvuOACX92mTRs1pmbNmqq3d+9e1XM/kyeYGgAAAAAAAAAAxAxuQgAAAAAAAAAAgEBwEwIAAAAAAAAAAASCmxAAAAAAAAAAACAQEQ2mtlgBIVbvrrvu8tW33HKLGtO9e3fVGzt2bLr7cOjQIdVbvXq16rlBUFYwtRW6GkluQJkVpmoFirrhctdee60as2HDhoztXIz47bff0h1jBTxaQXJuoFanTp3UGCswyA2+tkJ1QgnQtljBr6VLl1a9UqVK+erHH39cjbECZubMmZPutqzw89q1a6ueG+QTHx+vxljvmf/85z+qF8vef/99Xz1s2DA1ply5cqrXsWNH1XNDHq3gaDdsTkSka9euvtoKfLz00ktVzwo/CtJHH32kem7YpogOgbbCVQ8cOKB6jRs39tVu2PHpWPPQCteNJW7QkxVaZQW/W0GXblCWFQ5mBXMlJCSks5f2muIGgYmIrF+/3ldfd911akwoxykrNM5ab63Q2rp16/rqDh06qDFWINzatWt99bx589QYa+22QsVi3U8//ZTumLffflv1rO9/wIABvtoKmnTXNhGRZs2a+eoSJUqoMS1btlS9cEO/rbBz9/zAOpcMl7V+//nnn6rnBhGGGjQ7ZMiQDOxdbLLWBuvY4oZ+W+/n8uXLq567llrn2tb5YJkyZVQvFBs3blQ9N1jWCmH9448/VM8KKnSPn8nJyWqMdZ0TyXme1dx7772qd+LECdXr27dvxF4zlODXiRMnqp611rnH+UgGm1vHa+tY7M4p67qKYOoz9+KLL6qeOy/q1aunxljB4OGyguzPOy+8j5Kee+45X92nTx815p577lG9Bx54IKzXC4Ub7C4i8vPPPwf2etG0bt26dMfUqVNH9RYtWhTE7sQMa33v3Lmz6lnzoH///r7aWuvczw9ERLZs2ZLu61nXDtYx/Gxgfb70xRdfqF4o5/fWMenf//63r7bWsWhfq1nnXtb7b+rUqarnHotvvvlmNcb6zDNnzpy+2vrc8P7771c967pt5syZqnem+EsIAAAAAAAAAAAQCG5CAAAAAAAAAACAQHATAgAAAAAAAAAABIKbEAAAAAAAAAAAIBBxXggpHwcOHDADB2NB2bJlffXll1+uxljhcpdddpnqucEo+fLly+DenbnU1FRfvXz5cjXGCgF1A0vdQNNIS05Olvz58wf6Gqebd27ozIoVK9SY3Llzq54VYDhp0iRf7YbeiuggYREdHGyFTEabFVBrBftYwYruz8Fi/UzduXj11VeH9HpvvfVWuq9nCXreRXqts8JO3QDJbdu2qTFW0Jv7fT/88MNqzIwZM1TPCiZ0gzqt4E4r6NINh01MTFRjvvvuO9WbPXu26tWqVctXp6SkqDFjxoxRPSs4MmhZbd6FwgoDfvPNN1XPDee1/P7776pnhQdOmTLFV1u/83BZYfft27dXvezZs/tq6/v77bffVK9JkybpjomkzDzG5sqVy1evWbNGjbGCx1evXq16W7du9dUNGzZUY6w1yg1pbtq0qRqzZMkS1QtXKAGrlStXVmOsNcoNYBfR8+72229XY6xwvp07d/pqK0julVdeUb1wxfJa16ZNG9WbNWtWRnfptKzASjcoXERk/PjxqvfLL7/4aitQ0gqYPhdl5lpXuHBhX+0GhorY60yzZs0itm81a9b01StXrlRjDh8+rHpWoLV7jmaFbXbo0OEM9/B/5s2bp3oXXnih6v3jH/8Ia/vRFstrnSUhIUH1Nm3a5Kt//fVXNeaqq65SvXCvWa3rFXcNvuuuu8LatnX+aZ3DtW3bVvWs8N9QuMd961zWCmC1QrRDlVnzLpTzOus8yPpczf0M5LHHHlNj8ubNq3rWOpaVud+jFep73333qZ77eYr1frTmvnX+EYrMPMa665b1+U+7du1U79NPP1W9d99911dbx0DrMyc3yNkNFBcReeGFF1QvFlhh1d98842vvvbaa9WYxYsXp7tt69jw0UcfqZ41h0eNGpXu9tObd/wlBAAAAAAAAAAACAQ3IQAAAAAAAAAAQCC4CQEAAAAAAAAAAAKR5TMhIik+Pt5XW8//tZ5xF0mbN2/21bt37w709cKVmc+XczVv3lz1FixYoHrWM3nd54H37t1bjXn77bfT3YdYZWVCVK1aVfUGDhzoq63na1rP8atXr56v7tKlixozbdq0dPczVFntGa6hsNYZ61l7btbC8OHD1Rgr2yEWWOtmz549fXW1atXUGHdeiojs378/YvsVqrNx3lmKFy+ueo0aNfLV7jOIRUS+/vpr1XPzjWKF+yzWPHnyqDGxcNyNpWOsNS+GDh2qetbzRQ8dOuSr3ZwFEZGNGzeq3tGjR311KM8fjTT3+erWmmtlq7jnkpZVq1apnvVM2nfeecdXHzt2LN1tZ0RWW+us51UXK1bMV7vPwhbRmSMiOkvNPR8X+d/+I7Iyc61zz/lffvllNcbKDbKuC9z14YcffjjT3RQR+/nY//znP1UvlOtRKy/GWoNdVtaDlfc1cuRI1RsyZEi6248FWW2ts7Rq1cpXW/lrEydOVL0ePXqE9XrWmjh//nxffeedd4a1bfd4K2Jnmlx66aWq5z7/3HofW58LuNku1hgri8jK5gxVrMw761nzVg6ptf652RHWZw0NGjRIdx+yEiuTZdCgQb568ODBaoyVLTVixAhf/dxzz6kxJ0+ePNNdPK1Yup6wWOuRdf1fpUqVkPbD5WZATJgwIfSdy2RWtuiGDRt8tZWNYa1RFStW9NXW2vbTTz+pnpWjHMrnTWRCAAAAAAAAAACATMFNCAAAAAAAAAAAEAhuQgAAAAAAAAAAgEBwEwIAAAAAAAAAAASCYGqEJZZCbqywICuYxgqLbNy4sa/+9NNPQ9/BLKBs2bKqN3XqVNWrX7++r7YCkaxwpY4dO/rqjIR1hSJWAr1wbmHeIdpi6RiL03ODzkXswFj3PGXLli2B7VNGsNYh2jJzrStUqJCvrlatmhpjhTI+8cQTqueuBevXr1djrODglStX+uoQLstFxD5PP3jwYLpfZwVdutdCnTp1UmP++OMP1bOC4bdt25buPsSCs3Gts4Jxn3zySdUbMGCArx49enRI2//tt99U78MPP/TVvXr1CmlbociZM6fq3X333ap3xx13+OoKFSqoMSkpKarnfi6QmpqqxhQtWlT19u3bp3c2RLE87+6//37Vs+bPpk2bfHXbtm3VmG+//TasfYgF1157req9+OKLqle5cmVf/dZbb6kx1s/0999/z8Denbmz5XqidOnSvjpXrlxqzPbt21UvlBDlrMQNlR8/frwa44ZQi4gcO3bMV48aNUqNGTt2rOqFcl5hIZgaAAAAAAAAAABkCm5CAAAAAAAAAACAQHATAgAAAAAAAAAABIKbEAAAAAAAAAAAIBDnZfYOABllBSa/+uqrqte1a1fVe/rpp311jx491JgffvhB9UINjguSG9iVmJioxliBem6wj4j+fpYvX67G3HrrrarnhlMBAHCusALvzrYQPOBs5YYtL1myRI2xepMnT1a9Vq1a+erWrVurMXfddZfqWeGa0eb+HN544w015plnnlG9rBJCfa546qmnVO/iiy9WvWeffdZXJyQkqDEjR45UPev3vXfv3jPZxTNy9OhR1bPmofv9NGvWTI155JFHVO/KK6/01ZMmTVJjrED2s5X1s121apXqzZgxw1evXLlSjfnyyy9Vb968eb76v//9rxrzyy+/pLufGVGuXDlfbYXz3njjjaq3du1a1WvQoIGvto4ViByON/+zYsUKX33ppZdm0p5kDH8JAQAAAAAAAAAAAsFNCAAAAAAAAAAAEAhuQgAAAAAAAAAAgECQCYEsLzU1VfXuuece1Vu0aJHqTZkyxVdbz/w7ePCg6rnjIvkM6Ny5c6tehQoVVK9kyZJhbf+bb75Rvc6dO/vqpUuXhrVtAAAA4GxlPQd/woQJf1uL2PkP4Z7L58+fX/Xi4+PT/brDhw+r3rp163y1dV2F2GflFXbv3l31Tp486autLInGjRurXqdOnVRvy5YtZ7KLgShbtqyv7tOnjxrj5j+I6O978ODBkd2xs8CHH36oejVq1PDVN998sxpzww03qN6IESN8tZvLKSLy888/q56VHeF+DlOpUiU15qKLLlI9N7vHfS+IiAwYMED1xo4dq3rW1wIIDX8JAQAAAAAAAAAAAsFNCAAAAAAAAAAAEAhuQgAAAAAAAAAAgEBwEwIAAAAAAAAAAAQizrNSjBwHDhyQAgUKRGN/kEUkJyeboWiRFI15V7hwYV/drFkzNaZWrVqqV61aNV+dPXv2iO3T0aNHVS8pKUn1Nm3alO6YDRs2qN53332nelklhC7oecdaBwvzDtF2thxjkbWw1iHaWOuQGVjr/p8VOP3yyy+rXs6cOVXviy++8NXz589XY7766ivVcwOtk5OT1ZirrrpK9dq1a6d6N954o68+fvy4GvPAAw+o3muvvaZ6QTuX512xYsV8tRsSfbqeFZKeK1cuX33ixAk1xvoM5PPPP/fVjz/+uBqzY8cO1cvKOMYiM6Q37/hLCAAAAAAAAAAAEAhuQgAAAAAAAAAAgEBwEwIAAAAAAAAAAASCmxAAAAAAAAAAACAQBFMjLITcIDOcy4FeyDzMO0Qbx1hkBtY6RBtrHTIDa93fS0xMVL3u3bur3nXXXeera9WqpcbExcVFbL+s0ODp06f76hEjRqgxv//+e8T2ISOYd2cud+7cqleqVClfnZSUpMacPHkyqF3KUjjGIjMQTA0AAAAAAAAAADIFNyEAAAAAAAAAAEAguAkBAAAAAAAAAAACwU0IAAAAAAAAAAAQiPMyewcAAAAAAACQuayg36FDh6bbK1asmBpTrVo11StTpoyvLlKkiBqzcuVK1VuyZInqpaamqh7OHkeOHFG9DRs2ZMKeAIgU/hICAAAAAAAAAAAEgpsQAAAAAAAAAAAgENyEAAAAAAAAAAAAgSATAgAAAAAAAGHZtWtXSD0AwLmLv4QAAAAAAAAAAACB4CYEAAAAAAAAAAAIBDchAAAAAAAAAABAIEK6CeF5XtD7gSwmGnOCeQdX0HOCOQcL8w7RxjEWmYG1DtHGWofMwFqHzMC8Q7RxjEVmSG9OhHQT4uDBgxHZGZw9ojEnmHdwBT0nmHOwMO8QbRxjkRlY6xBtrHXIDKx1yAzMO0Qbx1hkhvTmRJwXwq2r1NRU2b59u+TLl0/i4uIitnPIejzPk4MHD0qpUqUkW7Zgn+bFvMMp0Zp3zDn8FfMO0cYxFpmBtQ7RxlqHzMBah8zAvEO0cYxFZgh13oV0EwIAAAAAAAAAAOBMEUwNAAAAAAAAAAACwU0IAAAAAAAAAAAQCG5CAAAAAAAAAACAQHATAgAAAAAAAAAABIKbEAAAAAAAAAAAIBDchAAAAAAAAAAAAIHgJgQAAAAAAAAAAAjE/wGbPgM9GQCSnQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Correct! üéâ"
          },
          "metadata": {},
          "execution_count": 119
        }
      ],
      "source": [
        "# TODO: Iterate through train_ds, displaying the image using plt.imshow() and printing the class\n",
        "# No answer checking here, you'll know you've done it right when you see 10 images with labels!\n",
        "import matplotlib.pyplot as plt\n",
        "# Number of images to display\n",
        "num_images = 10\n",
        "\n",
        "# Create a new figure\n",
        "plt.figure(figsize=(20, 4))\n",
        "\n",
        "for i in range(num_images):\n",
        "    # Access each image and label from the training dataset\n",
        "    image, label = train_ds[i]\n",
        "\n",
        "    # Reshape the image to a 2D array of size 28x28\n",
        "    image = image.reshape(28, 28)\n",
        "\n",
        "    # Create a subplot for each image\n",
        "    ax = plt.subplot(1, num_images, i + 1)\n",
        "\n",
        "    # Display the image\n",
        "    plt.imshow(image, cmap='gray')\n",
        "\n",
        "    # Display the label\n",
        "    ax.set_title(emoji_dataset.class_names[label])\n",
        "\n",
        "    # Hide grid lines\n",
        "    ax.grid(False)\n",
        "\n",
        "    # Hide axes ticks\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "\n",
        "plt.show()\n",
        "check('1.5.2', None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUK7QZ7iH3ZR"
      },
      "source": [
        "### Step 3: The `DataLoader` class\n",
        "Next, we will create a `DataLoader` object. Since deep learning models are typically trained in batches of data points, the `DataLoader` acts as a wrapper over the `Dataset` object and automatically aggregates data points into batches. It also can perform other useful functions like randomly shuffling the data points.\n",
        "\n",
        "Take a second and read over the PyTorch documentation for DataLoaders to get a sense of the API:\n",
        "\n",
        "https://pytorch.org/tutorials/beginner/basics/data_tutorial.html"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) Using the `EmojiDataset` class we mentioned above, create three `DataLoader` objects: one for training (call it `train_dataloader`), one for validation (`val_dataloader`), and one for testing (`test_dataloader`). (We've included the code for `train_dataloader`). Set the batch size as a variable `batch_size` to 64 and `shuffle=True`."
      ],
      "metadata": {
        "id": "eUYiDv-6SWJc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "3_CzfNX_PUEu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "outputId": "0c94316f-3c27-4a41-c47d-3f5d6725f1dc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Correct! üéâ"
          },
          "metadata": {},
          "execution_count": 120
        }
      ],
      "source": [
        "# TODO: Create three DataLoader objects\n",
        "batch_size = 64\n",
        "train_dataloader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
        "val_dataloader = torch.utils.data.DataLoader(val_ds, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "check('1.6.1', [train_dataloader, val_dataloader, test_dataloader])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: The Emoji MLP\n",
        "\n",
        "Now that we've defined how to load and generate data, let's create an MLP model specifically for the dataset.\n",
        "\n",
        "Note that there are a vast number of potential architectures that you can possibly choose from! Here, we describe a basic neural network that has two important specifications:\n",
        "\n",
        "- The number of input features is equal to the number of pixels in a sketch training example (784).\n",
        "- The number of output features is equal to the number of classes (10).\n",
        "\n",
        "**TODO**: Define a PyTorch `nn.Module` class (call it `EmojiMLP`) with the following specifications:\n",
        "- An linear layer with:\n",
        " - 784 input features\n",
        " - 64 output features\n",
        " - Followed by ReLU activation function\n",
        "- A second linear layer with:\n",
        " - 64 input features\n",
        " - 32 output features\n",
        " - Followed by ReLU activation function\n",
        "- An output linear layer with:\n",
        " - 32 input features\n",
        " - 10 output features\n",
        " - No activation function\n"
      ],
      "metadata": {
        "id": "JrnBj8vdhZoL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EmojiMLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(EmojiMLP, self).__init__()\n",
        "\n",
        "        # First linear layer\n",
        "        self.layer1 = nn.Linear(784, 64)\n",
        "\n",
        "        # Second linear layer\n",
        "        self.layer2 = nn.Linear(64, 32)\n",
        "\n",
        "        # Output layer\n",
        "        self.layer3 = nn.Linear(32, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # First linear layer followed by ReLU activation function\n",
        "        x = F.relu(self.layer1(x))\n",
        "\n",
        "        # Second linear layer followed by ReLU activation function\n",
        "        x = F.relu(self.layer2(x))\n",
        "\n",
        "        # Output layer with no activation function\n",
        "        x = self.layer3(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "model = EmojiMLP()\n",
        "check('1.6.2', model)"
      ],
      "metadata": {
        "id": "KcXatfcDhZH-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "outputId": "a40a7d1d-6136-41c2-ca61-0f91018efbd9"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Correct! üéâ"
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 3: Training (~10 min)\n",
        "\n",
        "### ‚úÖ Data + ‚úÖ Model + ‚òëÔ∏è Training = ‚ú®Ô∏è Success!\n",
        "\n",
        "The last piece of the pie is the training!\n",
        "\n",
        "However, for this week, we will not be going in detail about the training code üòÄ (we will next week!)\n",
        "\n",
        "Instead, we have provided the training code in the `train()` function in a script, `train.py`. You will simply have to provide the model and data into the `train()` function.\n",
        "\n"
      ],
      "metadata": {
        "id": "ZsKq87jiHEbN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) Train your model!\n",
        "\n",
        "Import the `train.py` file and call the `train()` function to train, and the `evaluate()` function to see how your model performs!\n",
        "\n",
        "We encourage you to take a look at `train.py`. In the left panel, click the folder icon üìÅ. Navigate to the folder `drive/MyDrive/DLE-Jun23/Projects/Week1`. Open the file `train.py`. The file should appear in the right panel of the notebook.\n"
      ],
      "metadata": {
        "id": "Pz5jKxA-TPHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from Week1.train import *\n",
        "emoji_model = EmojiMLP()\n",
        "train(model=emoji_model,\n",
        "      train_dataloader=train_dataloader,\n",
        "      val_dataloader=val_dataloader)\n",
        "\n",
        "accuracy = evaluate(emoji_model, test_dataloader)\n",
        "print(f\"Model accuracy: {accuracy}\")\n",
        "check('1.7.1', accuracy)"
      ],
      "metadata": {
        "id": "s8VNr7O0E-2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4) Play with your trained model\n",
        "\n",
        "Now all the hard work is paid off! Run the demo below."
      ],
      "metadata": {
        "id": "6B82kpgCTcDR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.special import softmax\n",
        "\n",
        "def get_prediction(doodle):\n",
        "  pt_input = torch.Tensor(doodle).view(1, doodle.shape[0]*doodle.shape[1])\n",
        "  y_hats = emoji_model(pt_input).detach().numpy()[0]\n",
        "  y_hats = softmax(y_hats)\n",
        "  return y_hats\n",
        "\n",
        "def predict(doodle):\n",
        "  if doodle is None:\n",
        "    return\n",
        "  doodle = doodle / 255.\n",
        "  y_hats = get_prediction(doodle)\n",
        "  emoji_names = np.array(list(DOODLE_TO_EMOJI_MAP.values()))\n",
        "  emoji_dict = {emoji_names[i]: float(y_hat) for i, y_hat in enumerate(y_hats)}\n",
        "  return emoji_dict\n",
        "\n",
        "interface = gr.Interface(predict, inputs='sketchpad', outputs='label', theme=\"default\", live=True, description=\"Guess the Doodle!\")\n",
        "interface.launch(debug=True)"
      ],
      "metadata": {
        "id": "aGgaGMj1Tq25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " üéäCongratulations üéä!\n",
        "\n",
        "You've finished the first week üí™.\n",
        "\n",
        "Head over to the Corise course website and submit your project!"
      ],
      "metadata": {
        "id": "mFBBya0kszzk"
      }
    }
  ]
}